{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f0bac3",
   "metadata": {},
   "source": [
    "# Módulo 2: Extração em Massa de Anúncios das Páginas de Busca do Airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411eea70",
   "metadata": {},
   "source": [
    "## 1. O Objetivo: Construir um Dataset do Zero\n",
    "\n",
    "Este notebook é o ponto de partida de todo o nosso projeto de dados. Sua missão é construir, do zero, um grande conjunto de dados (dataset) simulando um usuário que busca por acomodações no Airbnb.\n",
    "\n",
    "### O Desafio\n",
    "A análise de dados de aluguel por temporada depende de uma grande quantidade de informações. Como podemos coletar dados de preços e disponibilidade para centenas de datas diferentes, em múltiplos bairros, de forma automática? A resposta está na automação de buscas.\n",
    "\n",
    "### A Solução: Um Robô de Busca e Coleta em Larga Escala\n",
    "Este notebook funciona como um robô de busca. Nós o programamos com uma lista de locais e um período de tempo, e ele assume a tarefa de:\n",
    "1.  Visitar o Airbnb e pesquisar por estadias em cada um dos locais.\n",
    "2.  Para cada local, iterar dia a dia dentro dos meses definidos, realizando uma nova busca para cada data de check-in.\n",
    "3.  Em cada página de resultados, extrair as informações principais de cada anúncio (ID, título, avaliação, preço, link).\n",
    "4.  Navegar por todas as páginas de resultados (\"Próximo\", \"Próximo\", ...) até o fim.\n",
    "5.  Salvar os dados coletados de forma incremental em um único arquivo CSV, criando a base para as próximas etapas de análise e enriquecimento de dados.\n",
    "\n",
    "Vamos dar início à construção do nosso dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d827662",
   "metadata": {},
   "source": [
    "## 2. Preparando as Ferramentas para a Grande Busca\n",
    "\n",
    "Assim como no módulo anterior, o primeiro passo é importar nossa \"caixa de ferramentas\". As bibliotecas são as mesmas, pois as tarefas de automação web e manipulação de dados são semelhantes, mas aplicadas a um objetivo diferente: a coleta em massa a partir das páginas de busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bibliotecas para Manipulação de Dados e Arquivos ---\n",
    "import pandas as pd  # Essencial para organizar os dados coletados em uma tabela (DataFrame).\n",
    "import os            # Usado para interagir com o sistema operacional, especificamente para verificar se o arquivo de saída já existe.\n",
    "import re            # Biblioteca de Expressões Regulares, usada para extrair informações específicas de textos, como o ID do imóvel a partir do link.\n",
    "import time          # Permite adicionar pausas (esperas) no código, crucial para esperar o carregamento das páginas.\n",
    "from datetime import date, timedelta  # Usado para manipular e calcular datas, como o dia do check-in e do check-out.\n",
    "import calendar      # Usado para obter o número de dias em um determinado mês e ano.\n",
    "\n",
    "# --- Bibliotecas para Web Scraping e Automação ---\n",
    "from selenium import webdriver  # A ferramenta principal que controla o navegador.\n",
    "from selenium.webdriver.firefox.options import Options  # Permite configurar as opções do navegador (ex: modo headless).\n",
    "from selenium.webdriver.common.by import By  # Usado para especificar como encontrar elementos na página (por ID, XPath, CSS Selector, etc.).\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # Permite criar esperas inteligentes, aguardando que uma condição específica aconteça.\n",
    "from selenium.webdriver.support import expected_conditions as EC  # Contém a lista de condições possíveis para as esperas (ex: aguardar um elemento ficar visível).\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException  # Classes de erro do Selenium que usamos para tratar exceções, como um elemento não ser encontrado.\n",
    "from bs4 import BeautifulSoup  # Biblioteca para analisar (parse) o código HTML da página e facilitar a extração de dados dos anúncios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37f2f19",
   "metadata": {},
   "source": [
    "## 3. Ensinando o Robô a Pesquisar e Coletar\n",
    "\n",
    "Aqui está a função `buscar_e_extrair_airbnb`, o \"cérebro\" deste robô. Ela contém toda a lógica para realizar **uma busca completa** para um conjunto específico de parâmetros (local, datas e hóspedes).\n",
    "\n",
    "Seu trabalho é:\n",
    "1.  Construir a URL de busca correta.\n",
    "2.  Acessar a página.\n",
    "3.  Enquanto houver uma página de resultados, extrair os dados de todos os \"cards\" de anúncio.\n",
    "4.  Clicar no botão \"Próximo\" para avançar.\n",
    "5.  Repetir o processo até não haver mais páginas.\n",
    "6.  Ao final, devolver todos os dados coletados nessa busca em uma tabela organizada (DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar_e_extrair_airbnb(driver, local, data_checkin, data_checkout, numero_hospedes, max_paginas=None):\n",
    "    \"\"\"\n",
    "    Função para buscar hospedagens no Airbnb usando uma sessão de navegador existente.\n",
    "    Navega por páginas, extrai dados e retorna um DataFrame.\n",
    "    \"\"\"\n",
    "    # Cria uma lista vazia que irá armazenar os dados de todos os anúncios encontrados nesta busca.\n",
    "    dados_hospedagens = []\n",
    "\n",
    "    try:\n",
    "        # Formata as datas do formato DD/MM/AAAA para o formato AAAA-MM-DD, que é o padrão usado na URL do Airbnb.\n",
    "        checkin_iso = f\"{data_checkin[6:]}-{data_checkin[3:5]}-{data_checkin[:2]}\"\n",
    "        checkout_iso = f\"{data_checkout[6:]}-{data_checkout[3:5]}-{data_checkout[:2]}\"\n",
    "        # Monta a URL de busca final com todos os parâmetros.\n",
    "        url = (f\"https://www.airbnb.com.br/s/{local}/homes?checkin={checkin_iso}\"\n",
    "               f\"&checkout={checkout_iso}&adults={numero_hospedes}\")\n",
    "\n",
    "        print(f\"Acessando a URL: {url}\")\n",
    "        # Comanda o navegador para acessar a URL construída.\n",
    "        driver.get(url)\n",
    "\n",
    "        # Inicia um contador para as páginas de resultados.\n",
    "        pagina_atual = 1\n",
    "        # Inicia um loop infinito que só será quebrado quando não houver mais páginas ou ocorrer um erro.\n",
    "        while True:\n",
    "            # Condição de parada opcional: se um número máximo de páginas foi definido e atingido, para a extração.\n",
    "            if max_paginas is not None and pagina_atual > max_paginas:\n",
    "                print(f\"\\nLimite de {max_paginas} página(s) atingido. Finalizando extração para esta data.\")\n",
    "                break\n",
    "\n",
    "            print(f\"\\n--- Extraindo dados da página {pagina_atual} ---\")\n",
    "\n",
    "            # Bloco de espera inteligente: aguarda os 'cards' de anúncio aparecerem na tela.\n",
    "            try:\n",
    "                # Aguarda por até 20 segundos até que pelo menos um 'card' de anúncio esteja presente no HTML.\n",
    "                WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-testid='card-container']\"))\n",
    "                )\n",
    "                # Adiciona uma pausa estática de 5 segundos para garantir que todos os dados dentro dos cards sejam carregados.\n",
    "                time.sleep(5)\n",
    "            except TimeoutException:\n",
    "                # Se os 'cards' não carregarem em 20 segundos, exibe uma mensagem.\n",
    "                print(\"Tempo de espera excedido. Não foi possível carregar os anúncios.\")\n",
    "                # Tenta verificar se a página exibiu uma mensagem de \"Nenhum resultado\".\n",
    "                try:\n",
    "                    no_results_element = driver.find_element(By.CSS_SELECTOR, \"h1\")\n",
    "                    if \"Nenhum resultado\" in no_results_element.text:\n",
    "                        print(\"A página indica 'Nenhum resultado' para os filtros aplicados.\")\n",
    "                except NoSuchElementException:\n",
    "                    pass # Se não encontrar a mensagem, apenas continua.\n",
    "                break # Interrompe o loop 'while' para esta busca, pois não há anúncios.\n",
    "\n",
    "            # Pega o código-fonte HTML da página atual e o entrega ao BeautifulSoup.\n",
    "            page_source = driver.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            # Encontra todos os elementos <div> que correspondem a um 'card' de anúncio.\n",
    "            listings = soup.find_all('div', {'data-testid': 'card-container'})\n",
    "\n",
    "            # Se a lista de anúncios estiver vazia, encerra o loop para esta busca.\n",
    "            if not listings:\n",
    "                print(\"Nenhum anúncio encontrado nesta página, finalizando.\")\n",
    "                break\n",
    "\n",
    "            print(f\"Encontrados {len(listings)} anúncios na página {pagina_atual}.\")\n",
    "\n",
    "            # Itera sobre cada 'card' de anúncio encontrado na página.\n",
    "            for listing in listings:\n",
    "                # --- Extração dos dados de cada card ---\n",
    "                \n",
    "                # Encontra a tag 'a' que contém o link do anúncio.\n",
    "                link_tag = listing.find('a', href=True)\n",
    "                # Constrói o link completo e verifica se a tag foi encontrada.\n",
    "                link = \"https://www.airbnb.com.br\" + link_tag['href'] if link_tag and link_tag.get('href') else 'N/A'\n",
    "\n",
    "                # Extrai o ID do imóvel a partir do link usando expressões regulares.\n",
    "                imovel_id = 'N/A'\n",
    "                if link != 'N/A':\n",
    "                    id_match = re.search(r'/rooms/(\\d+)', link) # Procura por '/rooms/' seguido de um ou mais dígitos.\n",
    "                    if id_match:\n",
    "                        imovel_id = id_match.group(1) # Pega apenas o grupo de dígitos.\n",
    "\n",
    "                # Extrai o título do anúncio.\n",
    "                title_div = listing.find('div', {'data-testid': 'listing-card-title'})\n",
    "                title = title_div.text.strip() if title_div else 'N/A'\n",
    "\n",
    "                # Extrai o tipo de acomodação a partir do título.\n",
    "                tipo_acomodacao = 'N/A'\n",
    "                if ' em ' in title:\n",
    "                    tipo_acomodacao = title.split(' em ', 1)[0]\n",
    "\n",
    "                # Extrai a nota e a quantidade de avaliações.\n",
    "                nota_avaliacao, qtd_avaliacoes = 'N/A', 'N/A'\n",
    "                # O nome da classe pode mudar, então buscamos por uma parte que costuma ser constante.\n",
    "                rating_container = listing.find('span', class_=re.compile(r'r4a59j5'))\n",
    "                if rating_container:\n",
    "                    rating_span = rating_container.find('span', {'aria-hidden': 'true'})\n",
    "                    if rating_span:\n",
    "                        full_rating_text = rating_span.text.strip()\n",
    "                        # Trata o caso especial de anúncios \"Novos\" que não têm nota.\n",
    "                        if \"Novo\" in full_rating_text:\n",
    "                            nota_avaliacao, qtd_avaliacoes = 'Novo', '0'\n",
    "                        else:\n",
    "                            # Usa regex para extrair a nota (pode ter vírgula ou ponto).\n",
    "                            score_match = re.search(r'([\\d,.]+)', full_rating_text)\n",
    "                            if score_match: nota_avaliacao = score_match.group(1)\n",
    "                            # Usa regex para extrair a quantidade de avaliações (número entre parênteses).\n",
    "                            count_match = re.search(r'\\((\\d+)\\)', full_rating_text)\n",
    "                            if count_match: qtd_avaliacoes = count_match.group(1)\n",
    "\n",
    "                # Extrai o preço total e a quantidade de noites.\n",
    "                preco, qtd_noites = 'N/A', 'N/A'\n",
    "                price_row = listing.find('div', {'data-testid': 'price-availability-row'})\n",
    "                if price_row:\n",
    "                    full_price_text = price_row.get_text(separator=' ').strip()\n",
    "                    # Extrai o valor do preço.\n",
    "                    preco_match = re.search(r'R\\$\\s*([\\d.]+)', full_price_text)\n",
    "                    if preco_match:\n",
    "                        preco_str = preco_match.group(1).replace('.', '') # Remove o separador de milhar.\n",
    "                        preco = f\"R${preco_str}\"\n",
    "                    # Extrai o número de noites.\n",
    "                    noites_match = re.search(r'(\\d+)\\s*noites', full_price_text)\n",
    "                    if noites_match: qtd_noites = noites_match.group(1)\n",
    "\n",
    "                # Adiciona um dicionário com todos os dados extraídos à nossa lista principal.\n",
    "                dados_hospedagens.append({\n",
    "                    'ID Imóvel': imovel_id, 'Título': title, 'Tipo de Acomodação': tipo_acomodacao,\n",
    "                    'Data de Check-in': data_checkin, 'Data de Check-out': data_checkout,\n",
    "                    'Número de Hóspedes': numero_hospedes, 'Preço total': preco, 'Total de Noites': qtd_noites,\n",
    "                    'Avaliação': nota_avaliacao, 'Quantidade de Avaliações': qtd_avaliacoes, 'Link': link\n",
    "                })\n",
    "\n",
    "            # Tenta encontrar e clicar no botão \"Próximo\" para ir para a próxima página de resultados.\n",
    "            try:\n",
    "                next_button = driver.find_element(By.CSS_SELECTOR, \"a[aria-label='Próximo']\")\n",
    "                driver.execute_script(\"arguments[0].click();\", next_button) # Clica usando JavaScript.\n",
    "                pagina_atual += 1 # Incrementa o contador da página.\n",
    "            except NoSuchElementException:\n",
    "                # Se o botão \"Próximo\" não for encontrado, significa que chegamos à última página.\n",
    "                print(\"Não há mais páginas para extrair. Fim da extração para esta data.\")\n",
    "                break # Quebra o loop 'while'.\n",
    "    except Exception as e:\n",
    "        # Captura qualquer outro erro inesperado que possa acontecer durante a busca.\n",
    "        print(f\"Ocorreu um erro geral durante a extração: {e}\")\n",
    "\n",
    "    # Ao final, converte a lista de dicionários em um DataFrame do pandas e o retorna.\n",
    "    return pd.DataFrame(dados_hospedagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2d4a9",
   "metadata": {},
   "source": [
    "## 4. Orquestrando a Coleta em Massa: A Execução Principal\n",
    "\n",
    "Com nossa função de busca pronta, precisamos de um \"maestro\" para orquestrar a operação. Esta seção define os parâmetros da nossa grande busca e executa os loops que chamarão a função `buscar_e_extrair_airbnb` repetidamente para cada combinação de local e data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5930ac",
   "metadata": {},
   "source": [
    "### 4.1. Definindo os Parâmetros da Busca\n",
    "\n",
    "Este é o nosso painel de controle. Aqui, definimos para quais locais, meses, ano, e com qual duração de estadia o nosso robô deve realizar as buscas. O nome do arquivo de saída também será gerado dinamicamente com base nestes parâmetros para fácil identificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PAINEL DE CONTROLE DA BUSCA ---\n",
    "\n",
    "# Defina aqui a lista de locais que você deseja pesquisar.\n",
    "locais_busca = [\n",
    "    \"Copacabana, Rio de Janeiro\",\n",
    "    \"Ipanema, Rio de Janeiro\",\n",
    "    \"Barra da Tijuca, Rio de Janeiro\",\n",
    "    \"Leblon, Rio de Janeiro\"\n",
    "]\n",
    "# Defina a lista de meses para a busca (números de 1 a 12).\n",
    "meses_busca = [8, 9, 10, 11, 12]\n",
    "# Defina o ano da busca.\n",
    "ano_busca = 2025\n",
    "# Defina o número de hóspedes.\n",
    "hospedes = 1\n",
    "# Defina a duração da estadia em noites.\n",
    "duracao_estadia_em_noites = 4\n",
    "\n",
    "# --- GERAÇÃO AUTOMÁTICA DO NOME DO ARQUIVO ---\n",
    "# Cria um nome de arquivo descritivo e único, incluindo a data de hoje.\n",
    "nome_arquivo = f\"airbnb_dados_gerais_{hospedes}_hospede_{duracao_estadia_em_noites}_noites_{date.today().strftime('%Y_%m_%d')}.csv\"\n",
    "\n",
    "# --- INICIALIZAÇÃO DAS VARIÁVEIS DE CONTROLE ---\n",
    "# Inicia a variável do driver como 'None'. O navegador só será aberto quando for realmente necessário.\n",
    "driver = None\n",
    "# Inicia um contador de iterações para controlar quando o navegador deve ser reiniciado.\n",
    "iteration_counter = 0\n",
    "\n",
    "# Imprime uma mensagem inicial para o usuário.\n",
    "print(\"--- INICIANDO BUSCA EM MASSA ---\")\n",
    "print(f\"Os resultados serão salvos progressivamente em: '{nome_arquivo}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a39005",
   "metadata": {},
   "source": [
    "### 4.2. A Grande Maratona: Iterando por Locais, Meses e Dias\n",
    "\n",
    "Esta é a automação em sua forma mais pura. O código abaixo cria uma série de loops aninhados para garantir que todas as combinações de busca sejam executadas.\n",
    "\n",
    "Imagine uma equipe de pesquisa com uma lista de tarefas. O código funciona como o gerente dessa equipe, instruindo-a a:\n",
    "1.  Pegar o primeiro local (ex: \"Copacabana\").\n",
    "2.  Para esse local, pegar o primeiro mês da lista (ex: Agosto).\n",
    "3.  Para esse mês, pesquisar, um por um, todos os dias (de 1 a 31) como data de check-in.\n",
    "4.  Repetir o processo para todos os meses e, em seguida, para todos os locais da lista.\n",
    "\n",
    "Ele também gerencia a vida útil do navegador, reiniciando-o a cada 100 buscas para garantir a estabilidade do processo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82872b82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop 1: Itera sobre cada LOCAL da nossa lista de busca.\n",
    "for local in locais_busca:\n",
    "    # Loop 2: Itera sobre cada MÊS da nossa lista.\n",
    "    for mes in meses_busca:\n",
    "        # Obtém o número exato de dias no mês/ano atual (ex: 31 para Agosto, 30 para Setembro).\n",
    "        num_dias_no_mes = calendar.monthrange(ano_busca, mes)[1]\n",
    "\n",
    "        # Imprime um cabeçalho para indicar o início do processamento de um novo local/mês.\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"PROCESSANDO LOCAL: {local} | MÊS/ANO: {mes:02d}/{ano_busca}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        # Loop 3: Itera sobre cada DIA do mês atual.\n",
    "        for dia in range(1, num_dias_no_mes + 1):\n",
    "            # Incrementa o contador geral de iterações.\n",
    "            iteration_counter += 1\n",
    "\n",
    "            # Lógica para reiniciar o navegador a cada 100 buscas para liberar memória RAM.\n",
    "            if iteration_counter > 1 and (iteration_counter - 1) % 100 == 0:\n",
    "                if driver: # Verifica se existe um navegador aberto.\n",
    "                    print(f\"\\n--- [Iteração {iteration_counter - 1}] Reiniciando o navegador para liberar recursos ---\")\n",
    "                    driver.quit() # Fecha o navegador.\n",
    "                    driver = None # Define a variável como None para que um novo seja criado abaixo.\n",
    "\n",
    "            # Se não houver um navegador ativo (seja no início ou após uma reinicialização), cria um novo.\n",
    "            if driver is None:\n",
    "                print(\"\\n--- Iniciando uma nova sessão do navegador ---\")\n",
    "                options = Options()\n",
    "                options.add_argument('--headless')\n",
    "                options.add_argument('--disable-gpu')\n",
    "                options.add_argument('--no-sandbox')\n",
    "                options.add_argument('--disable-dev-shm-usage') # Configurações para otimizar a execução em ambientes de servidor/nuvem.\n",
    "                options.set_preference(\"permissions.default.image\", 2)\n",
    "                options.set_preference(\"permissions.default.stylesheet\", 2)\n",
    "                options.set_preference(\"gfx.downloadable_fonts.enabled\", False)\n",
    "                options.set_preference(\"media.autoplay.enabled\", False)\n",
    "                driver = webdriver.Firefox(options=options)\n",
    "\n",
    "            # Calcula as datas de check-in e check-out para a iteração atual.\n",
    "            data_de_checkin = date(ano_busca, mes, dia)\n",
    "            data_de_checkout = data_de_checkin + timedelta(days=duracao_estadia_em_noites)\n",
    "\n",
    "            # Formata as datas para o padrão DD/MM/AAAA.\n",
    "            checkin_str = data_de_checkin.strftime(\"%d/%m/%Y\")\n",
    "            checkout_str = data_de_checkout.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "            # Lógica para verificar se o período da estadia inclui um fim de semana (sábado ou domingo).\n",
    "            inclui_fim_de_semana = \"Não\"\n",
    "            for i in range(duracao_estadia_em_noites + 1):\n",
    "                dia_da_estadia = data_de_checkin + timedelta(days=i)\n",
    "                if dia_da_estadia.weekday() >= 5: # 5=Sábado, 6=Domingo.\n",
    "                    inclui_fim_de_semana = \"Sim\"\n",
    "                    break # Se encontrou um, não precisa verificar os outros dias.\n",
    "\n",
    "            print(f\"\\n--- Buscando dia {dia}/{num_dias_no_mes} para {local} | Check-in: {checkin_str} ---\")\n",
    "\n",
    "            # Chama a função principal de extração com os parâmetros da iteração atual.\n",
    "            df_resultado_diario = buscar_e_extrair_airbnb(\n",
    "                driver, local, checkin_str, checkout_str, hospedes\n",
    "                # A linha abaixo pode ser descomentada para testes rápidos, limitando a 1 página por busca.\n",
    "                # , max_paginas=1 \n",
    "            )\n",
    "\n",
    "            # Se a função retornou algum dado (o DataFrame não está vazio).\n",
    "            if not df_resultado_diario.empty:\n",
    "                # Adiciona as colunas 'Localização' e 'Inclui Fim de Semana' que são fixas para esta busca.\n",
    "                df_resultado_diario['Localização'] = local\n",
    "                df_resultado_diario['Inclui Fim de Semana'] = inclui_fim_de_semana\n",
    "\n",
    "                # Define a ordem desejada para as colunas no arquivo CSV final.\n",
    "                colunas_ordenadas = [\n",
    "                    'Localização', 'ID Imóvel', 'Título', 'Tipo de Acomodação',\n",
    "                    'Data de Check-in', 'Data de Check-out', 'Inclui Fim de Semana',\n",
    "                    'Número de Hóspedes', 'Preço total', 'Total de Noites', 'Avaliação',\n",
    "                    'Quantidade de Avaliações', 'Link'\n",
    "                ]\n",
    "                df_resultado_diario = df_resultado_diario[colunas_ordenadas]\n",
    "\n",
    "                # Verifica se o arquivo de saída já existe para decidir se o cabeçalho deve ser escrito.\n",
    "                escrever_cabecalho = not os.path.exists(nome_arquivo)\n",
    "\n",
    "                # Anexa os resultados da busca atual ao arquivo CSV.\n",
    "                df_resultado_diario.to_csv(\n",
    "                    nome_arquivo,\n",
    "                    mode='a', # 'a' significa 'append' (adicionar ao final do arquivo).\n",
    "                    header=escrever_cabecalho, # Só escreve o cabeçalho se o arquivo não existir.\n",
    "                    index=False, # Não salva o índice do DataFrame no arquivo.\n",
    "                    encoding='utf-8-sig' # Codificação que melhora a compatibilidade com o Excel.\n",
    "                )\n",
    "                print(f\"SUCESSO: {len(df_resultado_diario)} novos registros salvos em '{nome_arquivo}'\")\n",
    "            else:\n",
    "                # Se a busca não retornou nenhum anúncio.\n",
    "                print(f\"AVISO: Nenhum resultado encontrado para {checkin_str} em {local}.\")\n",
    "\n",
    "# --- Finalização do Script ---\n",
    "if driver: # Se, ao final de todos os loops, ainda houver um navegador aberto.\n",
    "    print(\"\\n--- Fechando a sessão final do navegador. ---\")\n",
    "    driver.quit() # Encerra o navegador e libera os recursos.\n",
    "\n",
    "print(\"\\n\\n--- EXTRAÇÃO EM MASSA CONCLUÍDA ---\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
