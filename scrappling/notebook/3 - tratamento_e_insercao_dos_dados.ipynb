{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df088861",
   "metadata": {},
   "source": [
    "# Módulo 3: Tratamento e Carga dos Dados no Banco de Dados (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ec010",
   "metadata": {},
   "source": [
    "## 1. O Ponto de Partida: Um Dataset Completo, Mas \"Plano\"\n",
    "\n",
    "Nos módulos anteriores, nossos robôs de web scraping trabalharam para criar um arquivo CSV completo, contendo uma vasta quantidade de informações sobre anúncios do Airbnb. Já temos os dados de busca (Módulo 2) e os detalhes de cada imóvel (Módulo 1).\n",
    "\n",
    "### O Desafio\n",
    "Apesar de completo, nosso dataset está em um formato \"plano\" (uma única grande tabela). Para análises eficientes e para a criação de aplicações robustas, este formato não é ideal. Ele contém muita informação repetida (como o nome da cidade em todas as linhas) e não está otimizado para consultas complexas.\n",
    "\n",
    "### A Solução: Normalização e Carga no Banco de Dados\n",
    "Este notebook executa o processo de **ETL (Extract, Transform, Load)**:\n",
    "1.  **Extract (Extrair):** Carregamos os dados brutos do nosso arquivo CSV consolidado.\n",
    "2.  **Transform (Transformar):** Limpamos e transformamos os dados. O passo mais importante aqui é a **normalização**, onde quebramos a grande tabela em várias tabelas menores e relacionadas (`cidade`, `bairro`, `imovel`, etc.), cada uma com uma responsabilidade única. Isso elimina a redundância e cria um modelo de dados relacional e eficiente.\n",
    "3.  **Load (Carregar):** Inserimos cada uma dessas novas tabelas tratadas em nosso banco de dados PostgreSQL, que servirá como nossa fonte de verdade centralizada e otimizada para futuras consultas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a610fb20",
   "metadata": {},
   "source": [
    "## 2. Preparando o Ambiente: Ferramentas de Dados e Conexão\n",
    "\n",
    "Para esta etapa, nossa \"caixa de ferramentas\" é mais focada. Precisamos do **Pandas** para a manipulação dos dados e das nossas funções customizadas do módulo `banco_de_dados`, que cuidam de toda a complexidade de se conectar ao banco e inserir os dados de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca pandas, essencial para manipulação de dados em formato de tabela (DataFrame).\n",
    "import pandas as pd\n",
    "\n",
    "# Importa as funções personalizadas que criamos para interagir com o banco de dados.\n",
    "# insere_dados_no_banco: envia um DataFrame para uma tabela no banco de dados.\n",
    "# retorna_tabela: busca todos os dados de uma tabela do banco e os retorna como um DataFrame.\n",
    "from funcoes.banco_de_dados import insere_dados_no_banco, retorna_tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0268d9",
   "metadata": {},
   "source": [
    "## 3. Extract: Carregando o Dataset Bruto\n",
    "\n",
    "A primeira etapa do nosso ETL é a **extração**. Vamos carregar o arquivo CSV, que é o resultado de todo o trabalho dos nossos scrapers, para a memória em um DataFrame do Pandas. A partir daqui, todas as transformações serão feitas neste DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16564c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o arquivo CSV contendo os dados brutos e completos e o carrega em um DataFrame chamado 'dados_brutos'.\n",
    "dados_brutos = pd.read_csv('dados/todos_dados/dados_completos_rio_de_janeiro.csv')\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame para uma verificação inicial dos dados.\n",
    "dados_brutos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8f6b4",
   "metadata": {},
   "source": [
    "## 4. Transform: Limpeza e Normalização dos Dados\n",
    "\n",
    "Esta é a etapa mais crítica do processo. Aqui, vamos limpar e transformar nosso grande e único DataFrame em várias tabelas menores e organizadas, prontas para serem inseridas no banco de dados relacional. Vamos criar uma tabela para cada entidade principal: `cidade`, `bairro`, `imovel`, `avaliacao`, `agendamento` e `anuncio`.\n",
    "\n",
    "### 4.1. Engenharia de Localização\n",
    "Primeiro, vamos tratar a coluna `Localização`. Ela contém o bairro e a cidade juntos. Vamos separá-los em colunas distintas para podermos criar nossas tabelas `cidade` e `bairro`. Também adicionaremos a coluna `estado`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc8f89",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza o acessador '.str.split()' para dividir a coluna 'Localização' em duas novas colunas ('bairro' e 'cidade').\n",
    "# O delimitador usado para a separação é ', ' (vírgula seguida de espaço).\n",
    "# 'expand=True' garante que o resultado seja expandido em novas colunas no DataFrame.\n",
    "dados_brutos[['bairro', 'cidade']] = dados_brutos['Localização'].str.split(', ', expand=True)\n",
    "\n",
    "# Aplica a função '.str.strip()' para remover quaisquer espaços em branco no início ou no fim das novas colunas.\n",
    "# Isso garante a consistência dos dados (ex: \" Copacabana\" se torna \"Copacabana\").\n",
    "dados_brutos['bairro'] = dados_brutos['bairro'].str.strip()\n",
    "dados_brutos['cidade'] = dados_brutos['cidade'].str.strip()\n",
    "\n",
    "# Cria uma nova coluna chamada 'estado' e atribui o valor fixo 'RJ' para todas as linhas.\n",
    "# Isso é feito pois todos os dados coletados neste projeto são do Rio de Janeiro.\n",
    "dados_brutos['estado'] = 'RJ'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0273ad30",
   "metadata": {},
   "source": [
    "### 4.2. Preparando e Carregando a Tabela `cidade`\n",
    "\n",
    "A tabela `cidade` é a mais simples. Ela conterá apenas uma lista de cidades únicas e seus respectivos estados. Isso evita que a gente repita \"Rio de Janeiro\" e \"RJ\" milhões de vezes no nosso banco de dados.\n",
    "\n",
    "O processo é:\n",
    "1.  Selecionar as colunas `cidade` e `estado`.\n",
    "2.  Remover as duplicatas, deixando apenas uma linha por cidade.\n",
    "3.  Renomear a coluna `cidade` para `nome`, para bater com o nosso modelo do banco.\n",
    "4.  Inserir no banco de dados.\n",
    "5.  Recuperar os dados do banco (com os IDs gerados) para usar nas próximas etapas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd77a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Preparação do DataFrame 'cidades' ---\n",
    "# Seleciona apenas as colunas 'cidade' e 'estado' do nosso DataFrame principal.\n",
    "cidades = dados_brutos[['cidade', 'estado']]\n",
    "# Remove todas as linhas duplicadas, resultando em uma lista de cidades únicas.\n",
    "cidades = cidades.drop_duplicates()\n",
    "# Renomeia a coluna 'cidade' para 'nome' para corresponder ao esquema da tabela no banco de dados. 'inplace=True' aplica a mudança diretamente.\n",
    "cidades.rename({'cidade':'nome'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 2. Carga no Banco de Dados ---\n",
    "# Chama nossa função personalizada para inserir o DataFrame 'cidades' na tabela 'cidade' do banco.\n",
    "insere_dados_no_banco(cidades, 'cidade')\n",
    "\n",
    "# --- 3. Verificação e Recuperação ---\n",
    "# Chama a função para buscar os dados recém-inseridos na tabela 'cidade'.\n",
    "# Agora, o DataFrame 'cidades' terá a coluna 'id' gerada automaticamente pelo banco, que usaremos como chave estrangeira.\n",
    "cidades = retorna_tabela('cidade')\n",
    "# Exibe o DataFrame recuperado para confirmar que a inserção funcionou.\n",
    "cidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426ab55",
   "metadata": {},
   "source": [
    "### 4.3. Preparando e Carregando a Tabela `bairro`\n",
    "\n",
    "Agora, faremos o mesmo para os bairros. A diferença crucial aqui é que precisamos relacionar cada bairro à sua cidade correspondente. Para isso, usaremos o `id` da cidade que acabamos de inserir no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd01e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Preparação do DataFrame 'bairros' ---\n",
    "# Seleciona as colunas 'bairro' e 'cidade' e remove as combinações duplicadas.\n",
    "bairros = dados_brutos[['bairro', 'cidade']].drop_duplicates()\n",
    "# Renomeia a coluna 'bairro' para 'nome'.\n",
    "bairros.rename({'bairro':'nome'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 2. Adicionando a Chave Estrangeira (cidade_id) ---\n",
    "# Usa a função 'pd.merge' para juntar o DataFrame de bairros com o de cidades (que já tem o 'id').\n",
    "# A junção é feita onde a coluna 'cidade' do df 'bairros' é igual à coluna 'nome' do df 'cidades'.\n",
    "bairrost = pd.merge(bairros, cidades, left_on='cidade', right_on='nome')\n",
    "# Renomeia as colunas resultantes para o padrão do banco ('id' vira 'cidade_id').\n",
    "bairrost.rename({'nome_x':'nome', 'id':'cidade_id'}, axis=1, inplace=True)\n",
    "# Seleciona apenas as colunas finais que serão inseridas na tabela 'bairro'.\n",
    "bairrost = bairrost[['nome', 'cidade_id']]\n",
    "\n",
    "# --- 3. Carga no Banco de Dados ---\n",
    "insere_dados_no_banco(bairrost, 'bairro')\n",
    "\n",
    "# --- 4. Verificação e Recuperação ---\n",
    "# Busca a tabela 'bairro' do banco para obter os IDs de cada bairro.\n",
    "bairros = retorna_tabela('bairro')\n",
    "# Exibe o resultado.\n",
    "bairros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea2cdde",
   "metadata": {},
   "source": [
    "### 4.4. Preparando e Carregando a Tabela `imovel`\n",
    "\n",
    "A tabela `imovel` conterá as características estáticas de cada propriedade única (tipo, quartos, camas, etc.). O processo envolve:\n",
    "1.  Selecionar as colunas relevantes.\n",
    "2.  Remover duplicatas baseadas no `ID Imóvel` para ter uma linha por imóvel.\n",
    "3.  Juntar (merge) com a tabela de bairros que acabamos de criar para obter a `bairro_id`.\n",
    "4.  Limpar os dados de quartos/camas/banheiros para conter apenas números.\n",
    "5.  Carregar no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Preparação do DataFrame 'imovel' ---\n",
    "# Seleciona as colunas com características fixas do imóvel.\n",
    "imovel = dados_brutos[['ID Imóvel', 'Tipo de Acomodação', 'Quartos', 'Camas', 'Banheiros', 'bairro']]\n",
    "# Remove duplicatas baseadas na coluna 'ID Imóvel' para garantir que cada imóvel apareça apenas uma vez.\n",
    "imovel = imovel.drop_duplicates('ID Imóvel')\n",
    "# Renomeia as colunas para o padrão do banco.\n",
    "imovel.rename({'ID Imóvel':'id_imovel', 'Tipo de Acomodação':'tipo_acomodacao'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 2. Adicionando a Chave Estrangeira (bairro_id) ---\n",
    "# Junta o DataFrame 'imovel' com o DataFrame 'bairros' (já com IDs do banco) para obter a 'bairro_id' de cada imóvel.\n",
    "imovelt = pd.merge(imovel, bairros, left_on='bairro', right_on='nome')\n",
    "# Renomeia as colunas para o padrão do banco.\n",
    "imovelt.rename({'id':'bairro_id','Quartos':'quartos' ,'Camas':'camas', 'Banheiros':'banheiros'}, axis=1, inplace=True)\n",
    "# Remove colunas que foram usadas apenas para a junção e não são necessárias na tabela final.\n",
    "imovelt = imovelt.drop(columns=['nome','bairro'])\n",
    "# Adiciona a 'cidade_id' diretamente, pois sabemos que todos os bairros pertencem à mesma cidade neste caso.\n",
    "imovelt['cidade_id'] = cidades['id'].iloc[0]\n",
    "\n",
    "\n",
    "# --- 3. Limpeza Final dos Dados ---\n",
    "# Itera sobre as colunas 'quartos', 'camas' e 'banheiros'.\n",
    "for col in ['quartos', 'camas', 'banheiros']:\n",
    "  # Usa regex para extrair apenas o primeiro conjunto de dígitos de cada string (ex: '2 camas' vira '2').\n",
    "  imovelt[col] = imovelt[col].str.extract('(\\\\d+)')\n",
    "\n",
    "# --- 4. Carga no Banco de Dados ---\n",
    "insere_dados_no_banco(imovelt, 'imovel')\n",
    "\n",
    "# --- 5. Verificação e Recuperação ---\n",
    "# Busca a tabela 'imovel' do banco para usá-la nas próximas junções.\n",
    "imovel = retorna_tabela('imovel')\n",
    "imovel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfa442",
   "metadata": {},
   "source": [
    "### 4.5. Preparando e Carregando a Tabela `avaliacao`\n",
    "\n",
    "Esta tabela isola as informações de avaliação, que podem variar para um mesmo imóvel.\n",
    "\n",
    "1.  Selecionar as colunas de avaliação.\n",
    "2.  Juntar com a tabela `imovel` para obter a `imovel_id` (chave estrangeira).\n",
    "3.  Limpar e converter os dados de `nota` e `qtd_avaliacoes` para os tipos numéricos corretos.\n",
    "4.  Carregar no banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c52b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Preparação do DataFrame 'avaliacao' ---\n",
    "# Seleciona as colunas relevantes e remove duplicatas.\n",
    "avaliacao = dados_brutos[['Quantidade de Avaliações', 'Avaliação', 'ID Imóvel']].drop_duplicates()\n",
    "# Renomeia as colunas para o padrão do banco.\n",
    "avaliacao.rename({'Quantidade de Avaliações':'qtd_avaliacoes', 'Avaliação':'nota', 'ID Imóvel': 'imovel_id'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 2. Adicionando a Chave Estrangeira (imovel_id) ---\n",
    "# Junta o DataFrame 'avaliacao' com 'imovel' (do banco) para obter o ID numérico correto para cada imóvel.\n",
    "avaliacaot = pd.merge(avaliacao, imovel[['id', 'id_imovel']], left_on='imovel_id', right_on='id_imovel')\n",
    "# Remove colunas de ID redundantes.\n",
    "avaliacaot = avaliacaot.drop(columns=['imovel_id', 'id_imovel'])\n",
    "# Renomeia a coluna 'id' (vinda da tabela imovel) para 'imovel_id', que é a chave estrangeira correta.\n",
    "avaliacaot.rename({'id':'imovel_id'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 3. Limpeza Final dos Dados ---\n",
    "# Preenche valores nulos (NaN) na quantidade de avaliações com 0.\n",
    "avaliacaot['qtd_avaliacoes'] = avaliacaot['qtd_avaliacoes'].fillna(0)\n",
    "# Converte a coluna para o tipo inteiro.\n",
    "avaliacaot['qtd_avaliacoes'] = avaliacaot['qtd_avaliacoes'].astype(int)\n",
    "# Na coluna 'nota', substitui a vírgula por ponto para permitir a conversão para número.\n",
    "avaliacaot['nota'] = avaliacaot['nota'].str.replace(',','.')\n",
    "# Substitui o texto 'Novo' (para anúncios sem avaliação) por 0.\n",
    "avaliacaot['nota'] = avaliacaot['nota'].replace('Novo',0)\n",
    "# Preenche quaisquer outros valores nulos com 0.\n",
    "avaliacaot['nota'] = avaliacaot['nota'].fillna(0)\n",
    "# Converte a coluna para o tipo float (número com casas decimais).\n",
    "avaliacaot['nota'] = avaliacaot['nota'].astype(float)\n",
    "\n",
    "# --- 4. Carga no Banco de Dados ---\n",
    "insere_dados_no_banco(avaliacaot, 'avaliacao')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c909d34",
   "metadata": {},
   "source": [
    "### 4.6. Preparando e Carregando a Tabela `agendamento`\n",
    "\n",
    "A tabela `agendamento` guarda as informações que mudam a cada busca: datas, preços para aquele período e número de hóspedes. É uma das tabelas mais dinâmicas do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfebcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Preparação do DataFrame 'agendamento' ---\n",
    "# Seleciona as colunas relevantes para o agendamento.\n",
    "agendamento = dados_brutos[['Número de Hóspedes', 'Data de Check-in', 'Data de Check-out', 'ID Imóvel', 'Preço total', 'Link']]\n",
    "# Remove duplicatas para ter apenas uma combinação única de imóvel-datas-preço.\n",
    "agendamento = agendamento.drop_duplicates()\n",
    "\n",
    "# --- 2. Limpeza e Transformação dos Dados ---\n",
    "# Converte as colunas de data (que estão como texto) para o tipo datetime do pandas. 'dayfirst=True' informa que o dia vem antes do mês (formato DD/MM/AAAA).\n",
    "agendamento['data_checkin'] = pd.to_datetime(agendamento['Data de Check-in'], dayfirst=True)\n",
    "agendamento['data_checkout'] = pd.to_datetime(agendamento['Data de Check-out'], dayfirst=True)\n",
    "# Calcula a duração da estadia subtraindo as datas e extraindo o número de dias.\n",
    "agendamento['total_noites'] = (agendamento['data_checkout'] - agendamento['data_checkin']).dt.days.astype(int)\n",
    "# Limpa a coluna de preço, removendo 'R$', espaços, e convertendo para número inteiro.\n",
    "agendamento['preco_total'] = agendamento['Preço total'].str.replace('R$', '', regex=False).str.strip().astype(float).astype(int)\n",
    "# Calcula o preço médio por dia.\n",
    "agendamento['preco_por_dia'] = (agendamento['preco_total'] / agendamento['total_noites']).round(2)\n",
    "\n",
    "# Renomeia as colunas para o padrão do banco.\n",
    "agendamento.rename({'Número de Hóspedes':'hospedes', 'Link':'link'}, axis=1, inplace=True)\n",
    "\n",
    "# --- 3. Adicionando a Chave Estrangeira (imovel_id) ---\n",
    "# Junta com a tabela 'imovel' para obter o ID correto de cada imóvel.\n",
    "agendamentot = pd.merge(agendamento, imovel[['id_imovel', 'id']], left_on='ID Imóvel', right_on='id_imovel')\n",
    "# Renomeia a coluna 'id' para 'imovel_id'.\n",
    "agendamentot.rename({'id':'imovel_id'}, axis=1, inplace=True)\n",
    "# Seleciona e reordena as colunas finais para inserção, removendo as colunas de junção.\n",
    "agendamentot = agendamentot[['hospedes', 'data_checkin', 'data_checkout', 'preco_por_dia','preco_total', 'link', 'imovel_id']]\n",
    "\n",
    "# --- 4. Carga no Banco de Dados ---\n",
    "insere_dados_no_banco(agendamentot,'agendamento')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e746559",
   "metadata": {},
   "source": [
    "### 4.7. Preparando e Carregando a Tabela `anuncio`\n",
    "\n",
    "Finalmente, a tabela `anuncio` é a nossa \"tabela fato\". Ela conecta todas as outras, ligando um `imovel` a um `agendamento` específico através de suas chaves estrangeiras. Cada linha aqui representa uma oferta única que foi encontrada em nossas buscas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0afbcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Recuperação e Preparação dos Dados ---\n",
    "# Primeiro, recuperamos a tabela 'agendamento' que acabamos de inserir, pois ela agora contém o 'id' único para cada agendamento.\n",
    "agendamento_db = retorna_tabela('agendamento')\n",
    "# Converte as colunas de data para o tipo datetime para garantir a correspondência na junção.\n",
    "agendamento_db['data_checkin'] = pd.to_datetime(agendamento_db['data_checkin'])\n",
    "agendamento_db['data_checkout'] = pd.to_datetime(agendamento_db['data_checkout'])\n",
    "\n",
    "# Prepara o DataFrame 'anuncio' a partir dos dados brutos.\n",
    "anuncio = dados_brutos[['Tipo de Acomodação', 'Link', 'ID Imóvel', 'Data de Check-in', 'Data de Check-out', 'Número de Hóspedes']]\n",
    "anuncio = anuncio.drop_duplicates()\n",
    "anuncio.rename({'Tipo de Acomodação':'titulo', 'Link':'link', 'Data de Check-in':'data_checkin', 'Data de Check-out':'data_checkout', 'Número de Hóspedes':'hospedes'}, axis=1, inplace=True)\n",
    "anuncio['data_checkin'] = pd.to_datetime(anuncio['data_checkin'], dayfirst=True)\n",
    "anuncio['data_checkout'] = pd.to_datetime(anuncio['data_checkout'], dayfirst=True)\n",
    "\n",
    "# --- 2. Adicionando as Chaves Estrangeiras ---\n",
    "# Junta 'anuncio' com 'imovel' para obter a 'imovel_id' do banco.\n",
    "anuncio_temp = pd.merge(anuncio, imovel[['id_imovel', 'id']], left_on='ID Imóvel', right_on='id_imovel')\n",
    "anuncio_temp.rename({'id':'imovel_id'}, axis=1, inplace=True)\n",
    "\n",
    "# Garante que os tipos das colunas de junção sejam os mesmos em ambos os DataFrames.\n",
    "anuncio_temp['imovel_id'] = anuncio_temp['imovel_id'].astype(int)\n",
    "agendamento_db['imovel_id'] = agendamento_db['imovel_id'].astype(int)\n",
    "\n",
    "# Junta o resultado anterior com 'agendamento_db' para obter a 'agendamento_id'.\n",
    "# A junção é complexa, usando múltiplas colunas para garantir que estamos ligando o anúncio à oferta exata.\n",
    "anunciot = pd.merge(anuncio_temp, agendamento_db[['id', 'imovel_id', 'data_checkin', 'data_checkout', 'hospedes', 'link']], on=['imovel_id', 'data_checkin', 'data_checkout', 'hospedes', 'link'])\n",
    "anunciot.rename({'id':'agendamento_id'}, axis=1, inplace=True)\n",
    "\n",
    "# Seleciona as colunas finais para a tabela 'anuncio'.\n",
    "anunciot = anunciot[['titulo', 'link', 'agendamento_id']]\n",
    "\n",
    "# --- 3. Carga no Banco de Dados ---\n",
    "insere_dados_no_banco(anunciot,'anuncio')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cdcfa1",
   "metadata": {},
   "source": [
    "## 5. Conclusão do Processo de ETL\n",
    "\n",
    "Com a execução da última célula, concluímos nosso pipeline de ETL. O que antes era um único e massivo arquivo CSV, agora é um conjunto de tabelas limpas, organizadas e inter-relacionadas dentro de um banco de dados PostgreSQL.\n",
    "\n",
    "Os dados estão agora em um formato ideal para:\n",
    "* **Consultas SQL complexas** para responder perguntas de negócio.\n",
    "* **Conexão com ferramentas de Business Intelligence** (como Power BI, Looker, etc.) para criar dashboards.\n",
    "* **Servir como fonte de dados para modelos de Machine Learning** e outras aplicações.\n",
    "\n",
    "O projeto de dados pode agora avançar para a fase de análise e geração de valor."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
