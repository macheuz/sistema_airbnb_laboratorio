{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544608e0",
   "metadata": {},
   "source": [
    "# Módulo de Funções: Conexão e Operações com o Banco de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8eef1",
   "metadata": {},
   "source": [
    "## 1. O Alicerce do Projeto: O Módulo de Banco de Dados\n",
    "\n",
    "Diferente dos notebooks anteriores, este não executa um processo de ponta a ponta. Ele é, na verdade, a documentação de um **módulo de funções reutilizáveis** (`banco_de_dados.py`), que serve como a fundação para todas as interações com nosso banco de dados PostgreSQL.\n",
    "\n",
    "### O Desafio\n",
    "Interagir com um banco de dados em múltiplos scripts pode ser repetitivo e arriscado. É preciso garantir que as conexões sejam abertas e fechadas corretamente, que as transações sejam confirmadas (`commit`) ou revertidas (`rollback`) em caso de erro, e que as operações sejam executadas da forma mais eficiente possível. Escrever esse código repetidamente aumenta a chance de erros.\n",
    "\n",
    "### A Solução: Uma Biblioteca Centralizada\n",
    "A solução é centralizar toda a lógica de comunicação com o banco de dados em um único local. Este módulo cria uma \"biblioteca\" de funções prontas para:\n",
    "* Abrir e fechar conexões de forma segura.\n",
    "* Ler tabelas inteiras para o Pandas.\n",
    "* Inserir grandes volumes de dados de forma ultraeficiente.\n",
    "* Excluir e atualizar registros em lote.\n",
    "\n",
    "Ao usar este módulo, nossos outros notebooks ficam mais limpos, legíveis e seguros, pois eles simplesmente chamam essas funções sem precisar se preocupar com os detalhes da implementação do banco de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9fe4f",
   "metadata": {},
   "source": [
    "## 2. As Ferramentas para Falar com o Banco\n",
    "\n",
    "Para construir nosso módulo, precisamos de algumas bibliotecas chave:\n",
    "* **psycopg2**: É o \"tradutor\" (driver) principal que permite que o Python \"converse\" com o banco de dados PostgreSQL.\n",
    "* **pandas**: Usado para receber os dados que vêm do banco em formato de tabela e para preparar os dados que serão enviados para o banco.\n",
    "* **io.StringIO**: Uma ferramenta inteligente que nos permite tratar um texto em memória como se fosse um arquivo, essencial para a nossa função de inserção em massa.\n",
    "* **logging**: Para criar um registro (log) de todas as operações, o que é fundamental para depurar problemas e monitorar a saúde do nosso pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca principal para conexão com o PostgreSQL.\n",
    "import psycopg2\n",
    "# Importa o submódulo 'extras' que contém funções otimizadas, como o 'execute_batch'.\n",
    "import psycopg2.extras\n",
    "# Importa a biblioteca pandas para manipulação de DataFrames.\n",
    "import pandas as pd\n",
    "# Importa a classe StringIO para criar um \"arquivo em memória\".\n",
    "from io import StringIO\n",
    "# Importa a biblioteca de logging para registrar eventos.\n",
    "import logging\n",
    "\n",
    "# Configura o sistema de logging para exibir mensagens de nível INFO ou superior.\n",
    "# O formato inclui a data/hora, o nível da mensagem (INFO, ERROR, etc.) e a própria mensagem.\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863abe6",
   "metadata": {},
   "source": [
    "## 3. As Funções Essenciais\n",
    "\n",
    "Esta seção detalha cada uma das funções que compõem nosso módulo.\n",
    "\n",
    "### 3.1. Abrindo e Fechando as Portas: Gestão da Conexão\n",
    "\n",
    "As duas funções mais básicas e talvez as mais importantes. `abre_conexao_banco_de_dados` contém as credenciais e a lógica para estabelecer a comunicação com o servidor PostgreSQL. `fecha_conexao_banco_de_dados` garante que essa comunicação seja encerrada corretamente, liberando recursos tanto no nosso script quanto no servidor do banco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d75c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abre_conexao_banco_de_dados():\n",
    "    \"\"\"\n",
    "    Estabelece uma conexão com o banco de dados PostgreSQL e retorna os objetos de conexão e cursor.\n",
    "    \"\"\"\n",
    "    # Bloco try...except para tratar possíveis erros de conexão (ex: senha errada, servidor offline).\n",
    "    try:\n",
    "        # Usa a função connect do psycopg2 com as credenciais do banco.\n",
    "        conn = psycopg2.connect(\n",
    "            host=\"localhost\",\n",
    "            database=\"planb\",\n",
    "            user=\"usuario\",\n",
    "            password=\"senha\",\n",
    "            port=5436\n",
    "        )\n",
    "        # Cria um objeto 'cursor', que é usado para executar comandos SQL no banco.\n",
    "        cursor = conn.cursor()\n",
    "        # Registra uma mensagem de sucesso no log.\n",
    "        logging.info(\"Conexão com o banco de dados estabelecida com sucesso.\")\n",
    "        # Retorna os dois objetos para serem usados por outras funções.\n",
    "        return conn, cursor\n",
    "    except psycopg2.Error as e:\n",
    "        # Se ocorrer um erro na conexão, registra o erro no log.\n",
    "        logging.error(f\"Erro ao conectar ao banco de dados: {e}\")\n",
    "        # Imprime o erro na tela para o usuário.\n",
    "        print(f\"Erro ao conectar ao banco de dados: {e}\")\n",
    "        # Retorna 'None' para indicar que a conexão falhou.\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def fecha_conexao_banco_de_dados(conn, cursor):\n",
    "    \"\"\"\n",
    "    Fecha o cursor e a conexão com o banco de dados.\n",
    "    \"\"\"\n",
    "    # Bloco try...except para tratar possíveis erros ao fechar.\n",
    "    try:\n",
    "        # Se o objeto cursor existir, fecha-o.\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        # Se o objeto de conexão existir, fecha-o.\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        # Registra a mensagem de sucesso no log.\n",
    "        logging.info(\"Conexão com o banco de dados fechada com sucesso.\")\n",
    "    except psycopg2.Error as e:\n",
    "        # Em caso de erro, registra no log e imprime na tela.\n",
    "        logging.error(f\"Erro ao fechar a conexão com o banco de dados: {e}\")\n",
    "        print(f\"Erro ao fechar a conexão com o banco de dados: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d0fc7",
   "metadata": {},
   "source": [
    "### 3.2. Lendo Dados: A Função `retorna_tabela`\n",
    "\n",
    "Esta função abstrai a tarefa de buscar todos os dados de uma tabela. Ela abre a conexão, executa um `SELECT *`, carrega os resultados em um DataFrame do Pandas (incluindo os nomes das colunas) e, por fim, garante o fechamento da conexão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retorna_tabela(nome_tabela, nome_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Conecta ao banco, lê uma tabela inteira e a retorna como um DataFrame do Pandas.\n",
    "    \"\"\"\n",
    "    # Chama a função para abrir a conexão e obter os objetos de conexão e cursor.\n",
    "    conn, cursor = abre_conexao_banco_de_dados()\n",
    "\n",
    "    # Verifica se a conexão foi estabelecida com sucesso.\n",
    "    if conn and cursor:\n",
    "        try:\n",
    "            # Monta a string da query SQL para selecionar todos os dados da tabela especificada.\n",
    "            sql = f'SELECT * FROM \"{nome_schema}\".\"{nome_tabela}\"'\n",
    "            # Imprime a query que será executada para fins de debug.\n",
    "            print(f\"Executando query: {sql}\")\n",
    "            logging.info(f\"Executando query: {sql}\")\n",
    "\n",
    "            # Executa a query no banco.\n",
    "            cursor.execute(sql)\n",
    "            # Busca todos os resultados da query executada.\n",
    "            dados = cursor.fetchall()\n",
    "            # Extrai os nomes das colunas a partir da descrição do cursor.\n",
    "            colunas = [desc[0] for desc in cursor.description]\n",
    "            # Cria o DataFrame do Pandas com os dados e os nomes das colunas.\n",
    "            df = pd.DataFrame(dados, columns=colunas)\n",
    "            \n",
    "            logging.info(f\"Tabela '{nome_tabela}' lida com sucesso, {len(df)} linhas retornadas.\")\n",
    "            # Retorna o DataFrame criado.\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            # Em caso de erro na leitura, registra e imprime a falha.\n",
    "            logging.error(f\"Erro ao ler a tabela '{nome_tabela}': {e}\")\n",
    "            print(f\"Erro ao ler a tabela: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            # A cláusula 'finally' garante que este bloco de código seja executado sempre, independentemente de ter havido erro ou não.\n",
    "            # É crucial para garantir que a conexão com o banco seja sempre fechada.\n",
    "            fecha_conexao_banco_de_dados(conn, cursor)\n",
    "    else:\n",
    "        # Se a conexão inicial falhou.\n",
    "        print(\"Não foi possível conectar ao banco de dados.\")\n",
    "        logging.error(\"Falha na leitura da tabela pois não foi possível conectar ao banco de dados.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d5ae8",
   "metadata": {},
   "source": [
    "### 3.3. Inserção em Massa: A Função `insere_dados_no_banco`\n",
    "\n",
    "Esta é a função mais importante para a performance do nosso ETL. Inserir milhões de linhas em um banco, uma por uma (`INSERT`), é extremamente lento. A solução é usar o comando `COPY` do PostgreSQL, que é otimizado para cargas de dados em massa.\n",
    "\n",
    "Esta função automatiza o processo:\n",
    "1.  Recebe um DataFrame do Pandas.\n",
    "2.  Converte o DataFrame em um formato CSV em memória (usando `StringIO`), sem precisar criar um arquivo físico.\n",
    "3.  Usa o método `copy_expert` do `psycopg2` para enviar esse \"arquivo em memória\" diretamente para o banco de dados através do comando `COPY`.\n",
    "4.  Gerencia a transação, confirmando (`commit`) em caso de sucesso ou revertendo (`rollback`) em caso de erro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_dados_no_banco(dados, tabela_destino, nome_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Recebe um DataFrame e insere seus dados em uma tabela do banco de dados\n",
    "    usando o método de alta performance COPY FROM.\n",
    "    \"\"\"\n",
    "    # Validação inicial: se o DataFrame estiver vazio, não faz nada.\n",
    "    if dados.empty:\n",
    "        print(\"DataFrame de entrada está vazio. Nenhuma inserção será realizada.\")\n",
    "        logging.warning(f\"Tentativa de inserção na tabela '{tabela_destino}' com DataFrame vazio.\")\n",
    "        return\n",
    "\n",
    "    # Inicializa as variáveis de conexão como None.\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    \n",
    "    # Bloco try...except...finally para garantir a gestão correta da conexão e transação.\n",
    "    try:\n",
    "        # Abre a conexão com o banco.\n",
    "        conn, cursor = abre_conexao_banco_de_dados()\n",
    "        if conn is None or cursor is None:\n",
    "            # Lança um erro se a conexão falhar.\n",
    "            raise ConnectionError(\"Falha ao abrir a conexão com o banco de dados.\")\n",
    "\n",
    "        # Cria um buffer de texto em memória. Funciona como um arquivo temporário que não é salvo no disco.\n",
    "        buffer = StringIO()\n",
    "        # Converte o DataFrame para um formato CSV e o escreve no buffer.\n",
    "        # index=False: não escreve o índice do DataFrame.\n",
    "        # header=False: não escreve o cabeçalho (nomes das colunas).\n",
    "        # sep=';': usa ponto e vírgula como delimitador.\n",
    "        dados.to_csv(buffer, index=False, header=False, sep=';', quotechar='\"')\n",
    "        # \"Rebobina\" o buffer para o início, para que o comando COPY possa lê-lo do começo.\n",
    "        buffer.seek(0)\n",
    "\n",
    "        # Monta a string dos nomes das colunas no formato \"(col1, col2, ...)\" para o comando SQL.\n",
    "        colunas_str = ', '.join(f'\"{col}\"' for col in dados.columns)\n",
    "        # Monta o comando COPY completo.\n",
    "        sql_copy_command = (\n",
    "            f'COPY \"{nome_schema}\".\"{tabela_destino}\" ({colunas_str}) '\n",
    "            f\"FROM STDIN WITH (FORMAT CSV, HEADER FALSE, DELIMITER ';', QUOTE '\\\"')\"\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Executando comando COPY para a tabela \\\"{nome_schema}\\\".\\\"{tabela_destino}\\\"\")\n",
    "        print(f\"Executando comando COPY para a tabela \\\"{nome_schema}\\\".\\\"{tabela_destino}\\\"\")\n",
    "\n",
    "        # Executa o comando COPY, passando o buffer como a fonte de dados (STDIN).\n",
    "        cursor.copy_expert(sql=sql_copy_command, file=buffer)\n",
    "        # Se o comando foi bem-sucedido, confirma a transação, tornando as inserções permanentes.\n",
    "        conn.commit()\n",
    "\n",
    "        # Prepara e exibe uma mensagem de sucesso.\n",
    "        mensagem_sucesso = f\"{cursor.rowcount} linhas inseridas com sucesso na tabela \\\"{nome_schema}\\\".\\\"{tabela_destino}\\\".\"\n",
    "        logging.info(mensagem_sucesso)\n",
    "        print(mensagem_sucesso)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Se qualquer erro ocorrer no bloco 'try', este bloco é executado.\n",
    "        if conn:\n",
    "            # Desfaz todas as alterações feitas nesta transação.\n",
    "            conn.rollback()\n",
    "        # Monta e exibe uma mensagem de erro.\n",
    "        mensagem_erro = f\"Ocorreu um erro ao inserir dados na tabela \\\"{nome_schema}\\\".\\\"{tabela_destino}\\\": {e}\"\n",
    "        print(mensagem_erro)\n",
    "        logging.error(mensagem_erro)\n",
    "        # Relança a exceção para que o script que chamou a função saiba que algo deu errado.\n",
    "        raise\n",
    "    finally:\n",
    "        # Garante que a conexão seja sempre fechada.\n",
    "        if conn:\n",
    "            fecha_conexao_banco_de_dados(conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092bf14",
   "metadata": {},
   "source": [
    "### 3.4. Excluindo Dados em Lote: A Função `excluir_linhas_por_dataframe`\n",
    "\n",
    "Esta função utilitária permite excluir registros de uma tabela no banco com base em uma lista de valores de um DataFrame. Por exemplo, podemos usá-la para deletar todos os registros de imóveis que foram removidos do site antes de inserir uma nova carga de dados. Ela usa um `DELETE ... WHERE ... IN`, que é eficiente para exclusões em lote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf7c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excluir_linhas_por_dataframe(df_referencia, coluna_df, tabela_alvo, coluna_tabela, nome_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Exclui linhas de uma tabela do banco de dados com base nos valores de uma coluna de um DataFrame.\n",
    "    \"\"\"\n",
    "    print(f\"--- Iniciando processo de EXCLUSÃO na tabela '{nome_schema}'.'{tabela_alvo}' ---\")\n",
    "\n",
    "    # Validações iniciais para evitar execuções desnecessárias ou com erro.\n",
    "    if df_referencia.empty:\n",
    "        print(\"O DataFrame de referência está vazio. Nenhuma exclusão será realizada.\")\n",
    "        return\n",
    "    if coluna_df not in df_referencia.columns:\n",
    "        raise ValueError(f\"A coluna '{coluna_df}' não foi encontrada no DataFrame de referência.\")\n",
    "\n",
    "    # Extrai os valores únicos da coluna do DataFrame que serão usados para a exclusão.\n",
    "    valores_para_excluir = df_referencia[coluna_df].dropna().unique().tolist()\n",
    "    if not valores_para_excluir:\n",
    "        print(f\"Nenhum valor válido encontrado na coluna '{coluna_df}' para exclusão.\")\n",
    "        return\n",
    "\n",
    "    conn, cursor = None, None\n",
    "    try:\n",
    "        conn, cursor = abre_conexao_banco_de_dados()\n",
    "        if conn is None or cursor is None:\n",
    "            raise ConnectionError(\"Não foi possível estabelecer conexão com o banco de dados.\")\n",
    "\n",
    "        # Monta a query de exclusão. A cláusula 'IN %s' permite passar uma tupla de valores.\n",
    "        query = f'DELETE FROM \"{nome_schema}\".\"{tabela_alvo}\" WHERE \"{coluna_tabela}\" IN %s'\n",
    "        # Converte a lista de valores para uma tupla, que é o formato esperado pelo psycopg2.\n",
    "        valores_tuple = tuple(valores_para_excluir)\n",
    "\n",
    "        print(f\"Preparando para excluir registros onde '{coluna_tabela}' corresponde a {len(valores_tuple)} valores únicos.\")\n",
    "        # Executa a query, passando a tupla de valores como parâmetro.\n",
    "        cursor.execute(query, (valores_tuple,))\n",
    "        # 'cursor.rowcount' retorna o número de linhas afetadas pelo último comando.\n",
    "        linhas_excluidas = cursor.rowcount\n",
    "        # Confirma a transação para tornar a exclusão permanente.\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Operação concluída. {linhas_excluidas} linha(s) foram excluídas com sucesso.\")\n",
    "        logging.info(f\"{linhas_excluidas} linha(s) excluídas da tabela '{nome_schema}'.'{tabela_alvo}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante a exclusão. A transação será revertida (rollback). Erro: {e}\")\n",
    "        logging.error(f\"Erro na exclusão da tabela '{tabela_alvo}': {e}. Transação revertida.\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            fecha_conexao_banco_de_dados(conn, cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff3d1c",
   "metadata": {},
   "source": [
    "### 3.5. Atualizando Registros em Lote: A Função `atualizar_dados_no_banco`\n",
    "\n",
    "Similar à exclusão, esta função é projetada para atualizar múltiplos registros de uma vez. Ela recebe um DataFrame contendo uma coluna \"chave\" (para o `WHERE`) e as colunas com os novos valores. Para otimizar a performance, ela utiliza o método `execute_batch` do psycopg2, que é projetado especificamente para executar o mesmo comando `UPDATE` várias vezes com dados diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizar_dados_no_banco(df_atualizacao, tabela_alvo, colunas_para_atualizar, coluna_chave, nome_schema=\"public\"):\n",
    "    \"\"\"\n",
    "    Atualiza registros em uma tabela do banco de dados com base em um DataFrame de entrada.\n",
    "    \"\"\"\n",
    "    print(f\"--- Iniciando processo de ATUALIZAÇÃO na tabela '{nome_schema}'.'{tabela_alvo}' ---\")\n",
    "\n",
    "    # Validações iniciais.\n",
    "    if df_atualizacao.empty:\n",
    "        print(\"O DataFrame de atualização está vazio. Nenhuma operação será realizada.\")\n",
    "        return\n",
    "    \n",
    "    # Verifica se todas as colunas necessárias para a atualização existem no DataFrame.\n",
    "    colunas_necessarias = colunas_para_atualizar + [coluna_chave]\n",
    "    for col in colunas_necessarias:\n",
    "        if col not in df_atualizacao.columns:\n",
    "            raise ValueError(f\"A coluna '{col}' necessária para a atualização não foi encontrada no DataFrame.\")\n",
    "\n",
    "    conn, cursor = None, None\n",
    "    try:\n",
    "        conn, cursor = abre_conexao_banco_de_dados()\n",
    "        if conn is None or cursor is None:\n",
    "            raise ConnectionError(\"Não foi possível estabelecer conexão com o banco de dados.\")\n",
    "\n",
    "        # Monta a cláusula SET da query de forma dinâmica (ex: \"col1\" = %s, \"col2\" = %s).\n",
    "        set_clause = \", \".join([f'\"{col}\" = %s' for col in colunas_para_atualizar])\n",
    "        # Monta a query UPDATE completa.\n",
    "        query = f'UPDATE \"{nome_schema}\".\"{tabela_alvo}\" SET {set_clause} WHERE \"{coluna_chave}\" = %s'\n",
    "\n",
    "        # Prepara os dados para a atualização, criando uma lista de tuplas.\n",
    "        # A ordem das colunas na tupla deve corresponder exatamente aos '%s' na query.\n",
    "        colunas_ordenadas = colunas_para_atualizar + [coluna_chave]\n",
    "        dados_para_atualizar = [tuple(row) for row in df_atualizacao[colunas_ordenadas].itertuples(index=False)]\n",
    "\n",
    "        print(f\"Preparando para atualizar {len(dados_para_atualizar)} registros.\")\n",
    "\n",
    "        # Usa execute_batch, que é otimizado para executar um comando (UPDATE) várias vezes com diferentes parâmetros.\n",
    "        psycopg2.extras.execute_batch(cursor, query, dados_para_atualizar)\n",
    "\n",
    "        # Recupera o número de linhas atualizadas.\n",
    "        linhas_atualizadas = cursor.rowcount\n",
    "        # Confirma a transação.\n",
    "        conn.commit()\n",
    "\n",
    "        print(f\"Operação concluída. {linhas_atualizadas} linha(s) foram atualizadas na tabela '{tabela_alvo}'.\")\n",
    "        logging.info(f\"{linhas_atualizadas} linha(s) atualizadas na tabela '{nome_schema}'.'{tabela_alvo}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro durante a atualização. A transação será revertida (rollback). Erro: {e}\")\n",
    "        logging.error(f\"Erro na atualização da tabela '{tabela_alvo}': {e}. Transação revertida.\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            fecha_conexao_banco_de_dados(conn, cursor)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
